{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "361d73a1",
   "metadata": {
    "papermill": {
     "duration": 0.007011,
     "end_time": "2024-04-08T18:51:47.130888",
     "exception": false,
     "start_time": "2024-04-08T18:51:47.123877",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbadbd56",
   "metadata": {
    "papermill": {
     "duration": 12.650384,
     "end_time": "2024-04-08T18:51:59.788340",
     "exception": false,
     "start_time": "2024-04-08T18:51:47.137956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torchmetrics\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d80cf24-13e8-480c-94eb-2982bb52510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d2de5d",
   "metadata": {
    "papermill": {
     "duration": 0.007241,
     "end_time": "2024-04-08T18:51:59.803571",
     "exception": false,
     "start_time": "2024-04-08T18:51:59.796330",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a32fb60",
   "metadata": {
    "papermill": {
     "duration": 0.016983,
     "end_time": "2024-04-08T18:51:59.828208",
     "exception": false,
     "start_time": "2024-04-08T18:51:59.811225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    SR = 32000\n",
    "    N_MFCC = 13\n",
    "    # Dataset\n",
    "    ROOT_FOLDER = './'\n",
    "    # Training\n",
    "    N_CLASSES = 2\n",
    "    BATCH_SIZE = 96\n",
    "    N_EPOCHS = 5\n",
    "    LR = 3e-4\n",
    "    # Others\n",
    "    SEED = 42\n",
    "    \n",
    "CONFIG = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6700bf8e-7f43-4eac-9bea-25eb1d95fb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CONFIG.SEED) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c02a7d-dfb6-4f8b-8df1-db2abaa1cb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('open/train.csv')\n",
    "train, val, _, _ = train_test_split(df, df['label'], test_size=0.2, random_state=CONFIG.SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629d3d15-b971-49e2-a410-71b4cd9cbcf4",
   "metadata": {},
   "source": [
    "## Data Pre-processing : MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bdd0ba-fe6e-4efa-b785-af0389c50b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40000it [16:57, 39.30it/s]\n",
      "7989it [04:42, 34.82it/s]"
     ]
    }
   ],
   "source": [
    "max_train_samples = 40000\n",
    "max_val_samples = 10000\n",
    "def get_mfcc_feature(df, max_num, train_mode=True):\n",
    "    features = []\n",
    "    labels = []\n",
    "    iter_num=0\n",
    "    for _, row in tqdm(df.iterrows()):\n",
    "        # librosa패키지를 사용하여 wav 파일 load\n",
    "        if iter_num >= max_num:\n",
    "          break\n",
    "        iter_num += 1\n",
    "        \n",
    "        path = 'open/' + row['path'][2:]\n",
    "        \n",
    "        y, sr = librosa.load(path, sr=CONFIG.SR)\n",
    "        \n",
    "        # librosa패키지를 사용하여 mfcc 추출\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=CONFIG.N_MFCC)\n",
    "        \n",
    "        if mfcc.shape[1] < 400:\n",
    "            pad_width = 400 - mfcc.shape[1]\n",
    "            pad_value = np.mean(mfcc, axis=1, keepdims=True)\n",
    "            pad_array = np.tile(pad_value, (1, pad_width))  # 패딩할 행 생성\n",
    "            mfcc = np.hstack((mfcc, pad_array))  # 패딩 추가\n",
    "        else:\n",
    "            mfcc = mfcc[0:80,0:400]\n",
    "        \n",
    "        mfcc = np.expand_dims(mfcc, axis = 0)\n",
    "        features.append(mfcc)\n",
    "\n",
    "        if train_mode:\n",
    "            label = row['label']\n",
    "            label_vector = np.zeros(CONFIG.N_CLASSES, dtype=float)\n",
    "            label_vector[0 if label == 'fake' else 1] = 1\n",
    "            labels.append(label_vector)\n",
    "\n",
    "    if train_mode:\n",
    "        return features, labels\n",
    "    return features\n",
    "\n",
    "train_mfcc, train_labels = get_mfcc_feature(train, max_train_samples, True)\n",
    "val_mfcc, val_labels = get_mfcc_feature(val,max_val_samples, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f677d961-2723-4928-a5d3-0dae82ca915d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of a single training sample:\", train_mfcc[0].shape)\n",
    "print(\"Shape of a single training label sample:\", train_labels[0].shape)\n",
    "\n",
    "print(\"Shape of a single validation sample:\", val_mfcc[0].shape)\n",
    "print(\"Shape of a single validation label sample:\", val_labels[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a682d49",
   "metadata": {
    "papermill": {
     "duration": 0.007331,
     "end_time": "2024-04-08T18:52:31.507909",
     "exception": false,
     "start_time": "2024-04-08T18:52:31.500578",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2459913-1bf6-40b9-b07d-402699590b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, mfcc, label):\n",
    "        self.mfcc = mfcc\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mfcc)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.label is not None:\n",
    "            return self.mfcc[index], self.label[index]\n",
    "        return self.mfcc[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7a462f-e4b3-44d8-8eef-16000d3124d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_mfcc, train_labels)\n",
    "val_dataset = CustomDataset(val_mfcc, val_labels)\n",
    "\n",
    "del train_mfcc\n",
    "del val_mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff1c7df-fbe7-4a61-9f66-c55138697eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CONFIG.BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=CONFIG.BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "del train_dataset\n",
    "del val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effb3435-cdb7-4a31-b7ef-fc16237cfc4a",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6494494-ce6f-460e-897f-ddbcb3c35ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ResNet Blocks and SE Blocks\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import math\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "                     \n",
    "class SELayer(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SELayer, self).__init__()\n",
    "        # print('se reduction: ', reduction)\n",
    "        # print(channel // reduction)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1) # F_squeeze \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):   # x: B*C*D*T\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class SEBasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, reduction=16):\n",
    "        super(SEBasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.se = SELayer(planes, reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.se(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 2\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class SEBottleneck(nn.Module):\n",
    "    expansion = 2\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, reduction=16):\n",
    "        super(SEBottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se = SELayer(planes * self.expansion, reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        out = self.se(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottle2neck(nn.Module):\n",
    "    expansion = 2\n",
    "\n",
    "    def __init__(self,\n",
    "                 inplanes,\n",
    "                 planes,\n",
    "                 stride=1,\n",
    "                 downsample=None,\n",
    "                 baseWidth=26,\n",
    "                 scale=4,\n",
    "                 stype='normal'):\n",
    "        \"\"\" Constructor\n",
    "        Args:\n",
    "            inplanes: input channel dimensionality\n",
    "            planes: output channel dimensionality\n",
    "            stride: conv stride. Replaces pooling layer.\n",
    "            downsample: None when stride = 1\n",
    "            baseWidth: basic width of conv3x3\n",
    "            scale: number of scale.\n",
    "            type: 'normal': normal set. 'stage': first block of a new stage.\n",
    "        \"\"\"\n",
    "        super(Bottle2neck, self).__init__()\n",
    "\n",
    "        width = int(math.floor(planes * (baseWidth / 64.0)))\n",
    "        self.conv1 = nn.Conv2d(inplanes,\n",
    "                               width * scale,\n",
    "                               kernel_size=1,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(width * scale)\n",
    "\n",
    "        if scale == 1:\n",
    "            self.nums = 1\n",
    "        else:\n",
    "            self.nums = scale - 1\n",
    "        if stype == 'stage':\n",
    "            self.pool = nn.AvgPool2d(kernel_size=3, stride=stride, padding=1)\n",
    "        convs = []\n",
    "        bns = []\n",
    "        for i in range(self.nums):\n",
    "            convs.append(\n",
    "                nn.Conv2d(width,\n",
    "                          width,\n",
    "                          kernel_size=3,\n",
    "                          stride=stride,\n",
    "                          padding=1,\n",
    "                          bias=False))\n",
    "            bns.append(nn.BatchNorm2d(width))\n",
    "        self.convs = nn.ModuleList(convs)\n",
    "        self.bns = nn.ModuleList(bns)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(width * scale,\n",
    "                               planes * self.expansion,\n",
    "                               kernel_size=1,\n",
    "                               bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stype = stype\n",
    "        self.scale = scale\n",
    "        self.width = width\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        spx = torch.split(out, self.width, 1)\n",
    "        for i in range(self.nums):\n",
    "            if i == 0 or self.stype == 'stage':\n",
    "                sp = spx[i]\n",
    "            else:\n",
    "                sp = sp + spx[i]\n",
    "            sp = self.convs[i](sp)\n",
    "            sp = self.relu(self.bns[i](sp))\n",
    "            if i == 0:\n",
    "                out = sp\n",
    "            else:\n",
    "                out = torch.cat((out, sp), 1)\n",
    "        if self.scale != 1 and self.stype == 'normal':\n",
    "            out = torch.cat((out, spx[self.nums]), 1)\n",
    "        elif self.scale != 1 and self.stype == 'stage':\n",
    "            out = torch.cat((out, self.pool(spx[self.nums])), 1)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class SEBottle2neck(nn.Module):\n",
    "    expansion = 2\n",
    "\n",
    "    def __init__(self,\n",
    "                 inplanes,\n",
    "                 planes,\n",
    "                 stride=1,\n",
    "                 downsample=None,\n",
    "                 baseWidth=26,\n",
    "                 scale=4,\n",
    "                 stype='normal'):\n",
    "        \"\"\" Constructor\n",
    "        Args:\n",
    "            inplanes: input channel dimensionality\n",
    "            planes: output channel dimensionality\n",
    "            stride: conv stride. Replaces pooling layer.\n",
    "            downsample: None when stride = 1\n",
    "            baseWidth: basic width of conv3x3\n",
    "            scale: number of scale.\n",
    "            type: 'normal': normal set. 'stage': first block of a new stage.\n",
    "        \"\"\"\n",
    "        super(SEBottle2neck, self).__init__()\n",
    "\n",
    "        width = int(math.floor(planes * (baseWidth / 64.0)))\n",
    "        self.conv1 = nn.Conv2d(inplanes,\n",
    "                               width * scale,\n",
    "                               kernel_size=1,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(width * scale)\n",
    "\n",
    "        if scale == 1:\n",
    "            self.nums = 1\n",
    "        else:\n",
    "            self.nums = scale - 1\n",
    "        if stype == 'stage':\n",
    "            self.pool = nn.AvgPool2d(kernel_size=3, stride=stride, padding=1)\n",
    "        convs = []\n",
    "        bns = []\n",
    "        for i in range(self.nums):\n",
    "            convs.append(\n",
    "                nn.Conv2d(width,\n",
    "                          width,\n",
    "                          kernel_size=3,\n",
    "                          stride=stride,\n",
    "                          padding=1,\n",
    "                          bias=False))\n",
    "            bns.append(nn.BatchNorm2d(width))\n",
    "        self.convs = nn.ModuleList(convs)\n",
    "        self.bns = nn.ModuleList(bns)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(width * scale,\n",
    "                               planes * self.expansion,\n",
    "                               kernel_size=1,\n",
    "                               bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
    "        self.se = SELayer(planes * self.expansion, reduction=16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stype = stype\n",
    "        self.scale = scale\n",
    "        self.width = width\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        #print('x: ', x.size())\n",
    "        out = self.conv1(x)\n",
    "        #print('conv1: ', out.size())\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        spx = torch.split(out, self.width, 1)\n",
    "        for i in range(self.nums):\n",
    "            if i == 0 or self.stype == 'stage':\n",
    "                sp = spx[i]\n",
    "            else:\n",
    "                sp = sp + spx[i]\n",
    "            sp = self.convs[i](sp)\n",
    "            sp = self.relu(self.bns[i](sp))\n",
    "            if i == 0:\n",
    "                out = sp\n",
    "            else:\n",
    "                out = torch.cat((out, sp), 1)\n",
    "        if self.scale != 1 and self.stype == 'normal':\n",
    "            out = torch.cat((out, spx[self.nums]), 1)\n",
    "        elif self.scale != 1 and self.stype == 'stage':\n",
    "            out = torch.cat((out, self.pool(spx[self.nums])), 1)\n",
    "\n",
    "        #print('conv2: ', out.size())\n",
    "        out = self.conv3(out)\n",
    "        #print('conv3: ', out.size())\n",
    "        out = self.bn3(out)\n",
    "        out = self.se(out)\n",
    "        #print('se :', out.size())\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d66fde-96f4-4560-bbd4-42b052672ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StatsPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StatsPooling, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        var = torch.sqrt((x - mean).pow(2).mean(-1) + 1e-5)\n",
    "        return torch.cat([mean.squeeze(-1), var], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15e87f2-e400-47bb-8f65-a35509f347db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "# from src.resnet_blocks import SELayer, BasicBlock, SEBasicBlock, Bottleneck, SEBottleneck, Bottle2neck, SEBottle2neck\n",
    "# from src.pooling import StatsPooling\n",
    "\n",
    "class Res2Net(nn.Module):\n",
    "    def __init__(self, block, layers, baseWidth=26, scale=4, m=0.35, num_classes=1000, loss='softmax', **kwargs):\n",
    "        self.inplanes = 16\n",
    "        super(Res2Net, self).__init__()\n",
    "        self.loss = loss\n",
    "        self.baseWidth = baseWidth\n",
    "        self.scale = scale\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(1, 16, 3, 1, 1, bias=False),\n",
    "                                   nn.BatchNorm2d(16), nn.ReLU(inplace=True),\n",
    "                                   nn.Conv2d(16, 16, 3, 1, 1, bias=False),\n",
    "                                   nn.BatchNorm2d(16), nn.ReLU(inplace=True),\n",
    "                                   nn.Conv2d(16, 16, 3, 1, 1, bias=False))\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU()\n",
    "        # self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 16, layers[0])#64\n",
    "        self.layer2 = self._make_layer(block, 32, layers[1], stride=2)#128\n",
    "        self.layer3 = self._make_layer(block, 64, layers[2], stride=2)#256\n",
    "        self.layer4 = self._make_layer(block, 128, layers[3], stride=2)#512\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        # self.stats_pooling = StatsPooling()\n",
    "\n",
    "        if self.loss == 'softmax':\n",
    "            # self.cls_layer = nn.Linear(2*8*128*block.expansion, num_classes)\n",
    "            self.cls_layer = nn.Linear(128*block.expansion, num_classes)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight,\n",
    "                                        mode='fan_out',\n",
    "                                        nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.AvgPool2d(kernel_size=stride,\n",
    "                             stride=stride,\n",
    "                             ceil_mode=True,\n",
    "                             count_include_pad=False),\n",
    "                nn.Conv2d(self.inplanes,\n",
    "                          planes * block.expansion,\n",
    "                          kernel_size=1,\n",
    "                          stride=1,\n",
    "                          bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(self.inplanes,\n",
    "                  planes,\n",
    "                  stride,\n",
    "                  downsample=downsample,\n",
    "                  stype='stage',\n",
    "                  baseWidth=self.baseWidth,\n",
    "                  scale=self.scale))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(\n",
    "                block(self.inplanes,\n",
    "                      planes,\n",
    "                      baseWidth=self.baseWidth,\n",
    "                      scale=self.scale))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward(self, x):\n",
    "        #x = x[:, None, ...]\n",
    "        x = self.conv1(x)\n",
    "        # print('conv1: ', x.size())\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        # x = self.maxpool(x)\n",
    "        # print('maxpool: ', x.size())\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        # print('layer1: ', x.size())\n",
    "        x = self.layer2(x)\n",
    "        # print('layer2: ', x.size())\n",
    "        x = self.layer3(x)\n",
    "        # print('layer3: ', x.size())\n",
    "        x = self.layer4(x)\n",
    "        # print('layer4: ', x.size())\n",
    "        # x = self.stats_pooling(x)\n",
    "        x = self.avgpool(x)\n",
    "        # print('avgpool:', x.size())\n",
    "        # x = x.view(x.size(0), -1)\n",
    "        x = torch.flatten(x, 1)\n",
    "        # print('flatten: ', x.size())\n",
    "        x = self.cls_layer(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return F.log_softmax(x, dim=-1)\n",
    "\n",
    "    def extract(self, x):\n",
    "        # x = x[:, None, ...]\n",
    "        x = self.conv1(x)\n",
    "        # print('conv1: ', x.size())\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        # print('layer1: ', x.size())\n",
    "        x = self.layer2(x)\n",
    "        # print('layer2: ', x.size())\n",
    "        x = self.layer3(x)\n",
    "        # print('layer3: ', x.size())\n",
    "        x = self.layer4(x)\n",
    "        # print('layer4: ', x.size())\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        # print('flatten: ', x.size())\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "    # Allow for accessing forward method in a inherited class\n",
    "    forward = _forward\n",
    "\n",
    "\n",
    "'''Res2Net models'''\n",
    "def res2net50_v1b(**kwargs):\n",
    "    \"\"\"Constructs a Res2Net-50_v1b model.\n",
    "    Res2Net-50 refers to the Res2Net-50_v1b_26w_4s.\n",
    "    \"\"\"\n",
    "    model = Res2Net(Bottle2neck, [3, 4, 6, 3], baseWidth=26, scale=4, **kwargs)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def se_res2net50_v1b(**kwargs):\n",
    "    \"\"\"Constructs a Res2Net-50_v1b model.\n",
    "    Res2Net-50 refers to the Res2Net-50_v1b_26w_4s.\n",
    "    \"\"\"\n",
    "    model = Res2Net(SEBottle2neck, [3, 4, 6, 3], baseWidth=26, scale=4, **kwargs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28c4a8c-0219-46bd-bd46-09d0327fe7eb",
   "metadata": {},
   "source": [
    "# Train & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b488cd03-608a-4711-8add-beae17924071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7253de-ce9a-45a8-b71f-7752e427941c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def train(model, optimizer, train_loader, val_loader, device):\n",
    "    model.to(device)\n",
    "    criterion = nn.BCELoss().to(device)\n",
    "    \n",
    "    best_val_score = 0\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(1, CONFIG.N_EPOCHS+1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        for features, labels in tqdm(iter(train_loader)):\n",
    "            features = features.float().to(device)\n",
    "            labels = labels.float().to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(features)\n",
    "            loss = criterion(output, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "                    \n",
    "        _val_loss, _val_score = validation(model, criterion, val_loader, device)\n",
    "        _train_loss = np.mean(train_loss)\n",
    "        print(f'Epoch [{epoch}], Train Loss : [{_train_loss:.5f}] Val Loss : [{_val_loss:.5f}] Val AUC : [{_val_score:.5f}]')\n",
    "            \n",
    "        if best_val_score < _val_score:\n",
    "            best_val_score = _val_score\n",
    "            best_model = model\n",
    "    \n",
    "    return best_model\n",
    "\n",
    "# def multiLabel_AUC(y_true, y_scores):\n",
    "#     auc_scores = []\n",
    "#     print(y_true)\n",
    "#     print(y_scores)\n",
    "#     for i in range(y_true.shape[1]):\n",
    "#         pred_class = np.where(y_scores > 0.5, 1 , 0)\n",
    "#         print(accuracy_score(y_true, pred_class))\n",
    "#         FPRs, TPRs, Thresholds = roc_curve(y_true, y_scores)\n",
    "#         plt.plot(FPRs, TPRs, label = 'ROC')\n",
    "#         plt.plot([0,1],[0,1],'--',label = '0.5')\n",
    "#         plt.legend()\n",
    "#         plt.xlabel(\"FPR\")\n",
    "#         plt.ylabel(\"TPR\")\n",
    "#         plt.xlim(0,1)\n",
    "#         plt.ylim(0,1)\n",
    "#         plt.show()\n",
    "#         auc = roc_auc_score(y_true[:, i], y_scores[:, i])\n",
    "#         auc_scores.append(auc)\n",
    "#     mean_auc_score = np.mean(auc_scores)\n",
    "#     return mean_auc_score\n",
    "\n",
    "def multiLabel_AUC(y_true, y_scores):\n",
    "    auc_scores = []\n",
    "    \n",
    "    for i in range(y_true.shape[1]):\n",
    "        print(f\"Label {i}\")\n",
    "        print(y_true[:, i])\n",
    "        print(y_scores[:, i])\n",
    "        \n",
    "        # Compute ROC curve and AUC score for each label\n",
    "        fpr, tpr, _ = roc_curve(y_true[:, i], y_scores[:, i])\n",
    "        auc = roc_auc_score(y_true[:, i], y_scores[:, i])\n",
    "        auc_scores.append(auc)\n",
    "        \n",
    "        # Plotting ROC curve\n",
    "        plt.plot(fpr, tpr, label=f'ROC curve (area = {auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlabel(\"FPR\")\n",
    "        plt.ylabel(\"TPR\")\n",
    "        plt.xlim(0, 1)\n",
    "        plt.ylim(0, 1)\n",
    "        plt.title(f\"ROC curve for label {i}\")\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "    \n",
    "    mean_auc_score = np.mean(auc_scores)\n",
    "    return mean_auc_score\n",
    "    \n",
    "def validation(model, criterion, val_loader, device):\n",
    "    model.eval()\n",
    "    val_loss, all_labels, all_probs = [], [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for features, labels in tqdm(iter(val_loader)):\n",
    "            features = features.float().to(device)\n",
    "            labels = labels.float().to(device)\n",
    "            \n",
    "            probs = model(features)\n",
    "            #probs = torch.sigmoid(probs)\n",
    "            \n",
    "            loss = criterion(probs, labels)\n",
    "\n",
    "            val_loss.append(loss.item())\n",
    "\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "            all_probs.append(probs.cpu().numpy())\n",
    "        \n",
    "        _val_loss = np.mean(val_loss)\n",
    "\n",
    "        all_labels = np.concatenate(all_labels, axis=0)\n",
    "        all_probs = np.concatenate(all_probs, axis=0)\n",
    "        \n",
    "        # Calculate AUC score\n",
    "        auc_score = multiLabel_AUC(all_labels, all_probs)\n",
    "    \n",
    "    return _val_loss, auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a482219-ce5e-47ce-90cc-564ceb4e46ff",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d73f7b1-e261-4627-8897-00ea68a83259",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScheduledOptim(object):\n",
    "    \"\"\" A simple wrapper class for learning rate scheduling \"\"\"\n",
    "\n",
    "    def __init__(self, optimizer, n_warmup_steps):\n",
    "        self.optimizer = optimizer\n",
    "        self.d_model = 64\n",
    "        self.n_warmup_steps = n_warmup_steps\n",
    "        self.n_current_steps = 0\n",
    "        self.delta = 1\n",
    "\n",
    "    def step(self):\n",
    "        \"Step by the inner optimizer\"\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def zero_grad(self):\n",
    "        \"Zero out the gradients by the inner optimizer\"\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "    def increase_delta(self):\n",
    "        self.delta *= 2\n",
    "\n",
    "    def update_learning_rate(self):\n",
    "        \"Learning rate scheduling per step\"\n",
    "\n",
    "        self.n_current_steps += self.delta\n",
    "        new_lr = np.power(self.d_model, -0.5) * np.min([\n",
    "            np.power(self.n_current_steps, -0.5),\n",
    "            np.power(self.n_warmup_steps, -1.5) * self.n_current_steps])\n",
    "\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = new_lr\n",
    "        return new_lr\n",
    "\n",
    "    def state_dict(self):\n",
    "        ret = {\n",
    "            'd_model': self.d_model,\n",
    "            'n_warmup_steps': self.n_warmup_steps,\n",
    "            'n_current_steps': self.n_current_steps,\n",
    "            'delta': self.delta,\n",
    "        }\n",
    "        ret['optimizer'] = self.optimizer.state_dict()\n",
    "        return ret\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        self.d_model = state_dict['d_model']\n",
    "        self.n_warmup_steps = state_dict['n_warmup_steps']\n",
    "        self.n_current_steps = state_dict['n_current_steps']\n",
    "        self.delta = state_dict['delta']\n",
    "        self.optimizer.load_state_dict(state_dict['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97644a0-2385-4e16-ab02-ecf787ac061c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = se_res2net50_v1b(pretrained=False, num_classes=2)\n",
    "#optimizer = torch.optim.Adam(params = model.parameters(), eps=1e-09, weight_decay=1e-4, lr=3e-4, amsgrad=True)\n",
    "\n",
    "optimizer = ScheduledOptim(\n",
    "            torch.optim.Adam(\n",
    "            filter(lambda p: p.requires_grad, model.parameters()),\n",
    "            betas=(0.9, 0.98), eps=1e-09, weight_decay=1e-4, lr=3e-4, amsgrad=True),\n",
    "            1000) #1000: n_warmup_steps\n",
    "infer_model = train(model, optimizer, train_loader, val_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a978b0e6-b773-423a-93e4-ce463f4d4d84",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5889b493-d760-4cac-9ced-c3715195e8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for features in tqdm(iter(test_loader)):\n",
    "            features = features.float().to(device)\n",
    "            \n",
    "            probs = model(features)\n",
    "\n",
    "            probs  = probs.cpu().detach().numpy()\n",
    "            predictions += probs.tolist()\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1481da9a-bd4b-434e-88cf-1f9d6e9a76c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_size: 전체 train.csv 중 test에 사용할 행 비율\n",
    "test = pd.read_csv('open/test.csv')\n",
    "\n",
    "test_mfcc = get_mfcc_feature(test,50000, False)\n",
    "test_dataset = CustomDataset(test_mfcc, None)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=CONFIG.BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "preds = inference(infer_model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b80d70-a0b8-44b0-a396-daa70f991232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2차원 리스트를 numpy 배열로 변환\n",
    "data_array = np.array(preds)\n",
    "\n",
    "# logit 함수 정의\n",
    "def logit(x):\n",
    "    res=x*(-1)\n",
    "    res=np.log(res / (1 - res))\n",
    "    return res\n",
    "\n",
    "# numpy 배열에 logit 함수 적용\n",
    "logit_data = logit(data_array)\n",
    "\n",
    "print(logit_data/3)\n",
    "\n",
    "threshold = 0.5\n",
    "new_data = (logit_data > threshold).astype(int)\n",
    "\n",
    "print(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cc3322-d0ff-45e3-bc75-f5d0d047523e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('open/test.csv')\n",
    "\n",
    "index_id = test.iloc[:,0]\n",
    "\n",
    "submit = pd.DataFrame(new_data, index = index_id, columns=['fake', 'real'])\n",
    "\n",
    "# 결과 출력 및 CSV 파일로 저장\n",
    "print(submit.head())\n",
    "submit.to_csv('open/submit_SpecRNet.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8068726,
     "sourceId": 70203,
     "sourceType": "competition"
    },
    {
     "datasetId": 4732842,
     "sourceId": 8066583,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30674,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1830.928153,
   "end_time": "2024-04-08T19:22:15.265404",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-08T18:51:44.337251",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "01a8f214ec354c44b73d439565382278": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "06a1ede084cd487ebf3c469be657b53e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_80013ce73542415e82be091acccb89fe",
        "IPY_MODEL_d280070ca871485fbd2b7d34b1c9fd10",
        "IPY_MODEL_8212bde7695f494cbabea66983e4cf29"
       ],
       "layout": "IPY_MODEL_c4da594b806c4c2bbff6e8cdaf6088eb"
      }
     },
     "37e28ba3d8564da4a3257c3729310584": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "80013ce73542415e82be091acccb89fe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_95e72a34a4374fd5b4b147772085bb7c",
       "placeholder": "​",
       "style": "IPY_MODEL_37e28ba3d8564da4a3257c3729310584",
       "value": "model.safetensors: 100%"
      }
     },
     "8212bde7695f494cbabea66983e4cf29": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d9e4e04bb60e40d6b46d782f8156d05f",
       "placeholder": "​",
       "style": "IPY_MODEL_b1fa83d0511a4d8a910b8fdb40d32c29",
       "value": " 36.5M/36.5M [00:01&lt;00:00, 41.1MB/s]"
      }
     },
     "95e72a34a4374fd5b4b147772085bb7c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b1fa83d0511a4d8a910b8fdb40d32c29": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c4da594b806c4c2bbff6e8cdaf6088eb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d280070ca871485fbd2b7d34b1c9fd10": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_01a8f214ec354c44b73d439565382278",
       "max": 36494688,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_dcd2393d73d14514851a7d9ef50315fc",
       "value": 36494688
      }
     },
     "d9e4e04bb60e40d6b46d782f8156d05f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dcd2393d73d14514851a7d9ef50315fc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
